{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf93105-97ff-40a5-996a-d0c55c40eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0.0->datasets) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 4.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 4.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 4.7/110.9 MB 22.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 11.5/110.9 MB 27.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 18.9/110.9 MB 30.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 20.2/110.9 MB 25.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 20.7/110.9 MB 22.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 23.6/110.9 MB 19.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 27.5/110.9 MB 19.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 31.5/110.9 MB 19.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 37.0/110.9 MB 20.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 42.5/110.9 MB 20.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 47.7/110.9 MB 21.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 55.6/110.9 MB 22.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 64.0/110.9 MB 24.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 70.8/110.9 MB 24.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 76.5/110.9 MB 25.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 81.5/110.9 MB 25.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 89.4/110.9 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 94.6/110.9 MB 25.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 98.0/110.9 MB 25.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 100.1/110.9 MB 24.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 104.3/110.9 MB 24.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.6/110.9 MB 24.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 24.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 110.9/110.9 MB 23.6 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, safetensors, dill, torch, multiprocess, huggingface-hub, tokenizers, accelerate, transformers, datasets\n",
      "\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ------------ ---------------------------  3/10 [torch]\n",
      "   ---------------- -----------------------  4/10 [multiprocess]\n",
      "   -------------------- -------------------  5/10 [huggingface-hub]\n",
      "   -------------------- -------------------  5/10 [huggingface-hub]\n",
      "   -------------------- -------------------  5/10 [huggingface-hub]\n",
      "   ---------------------------- -----------  7/10 [accelerate]\n",
      "   ---------------------------- -----------  7/10 [accelerate]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   -------------------------------- -------  8/10 [transformers]\n",
      "   ------------------------------------ ---  9/10 [datasets]\n",
      "   ------------------------------------ ---  9/10 [datasets]\n",
      "   ------------------------------------ ---  9/10 [datasets]\n",
      "   ------------------------------------ ---  9/10 [datasets]\n",
      "   ---------------------------------------- 10/10 [datasets]\n",
      "\n",
      "Successfully installed accelerate-1.12.0 datasets-4.4.2 dill-0.4.0 huggingface-hub-0.36.0 multiprocess-0.70.18 safetensors-0.7.0 tokenizers-0.22.2 torch-2.9.1 transformers-4.57.3 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\maury\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'C:\\Users\\maury\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'C:\\Users\\maury\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'C:\\Users\\maury\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\maury\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 6.0.7 requires ipython!=8.17.1,<9.0.0,>=8.13.0; python_version > \"3.8\", but you have ipython 9.4.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets torch accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf89dc74-d17a-405d-a3b0-b49f80815f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (2.9.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (2.2.6)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: click in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\maury\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch nltk numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb43c009-042f-4b0a-beb1-1214352edbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maury\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maury\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##2. Import Libraries\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc14822-ab2d-4c6f-9e0c-f13975678cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. Load intents.json (FIXED CODE)\n",
    "with open(\"dataset/intents.json\", \"r\") as f:\n",
    "    intents = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40432f9d-1fd5-4b29-ad49-a4be51d8c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##4. Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "\n",
    "for intent in intents[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        documents.append((word_list, intent[\"tag\"]))\n",
    "        if intent[\"tag\"] not in classes:\n",
    "            classes.append(intent[\"tag\"])\n",
    "\n",
    "words = sorted(set([lemmatizer.lemmatize(w.lower()) for w in words if w.isalnum()]))\n",
    "classes = sorted(set(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14e7eef-9b50-4d04-b493-dc0835d1ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##5. Training Data\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    word_patterns = [lemmatizer.lemmatize(w.lower()) for w in doc[0]]\n",
    "    for w in words:\n",
    "        bag.append(1 if w in word_patterns else 0)\n",
    "\n",
    "    output = output_empty[:]\n",
    "    output[classes.index(doc[1])] = 1\n",
    "    training.append((bag, output))\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "X = np.array(list(training[:, 0]))\n",
    "y = np.array(list(training[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ea6853-b7e6-48cd-b3ff-2d311d241529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model folder ready ✅\n",
      "Metadata saved successfully ✅\n"
     ]
    }
   ],
   "source": [
    "##6. Save Metadata (IMPORTANT)\n",
    "import os\n",
    "\n",
    "os.makedirs(\"saved_model\", exist_ok=True)\n",
    "print(\"saved_model folder ready ✅\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(words, open(\"saved_model/words.pkl\", \"wb\"))\n",
    "pickle.dump(classes, open(\"saved_model/classes.pkl\", \"wb\"))\n",
    "\n",
    "print(\"Metadata saved successfully ✅\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614ee355-9490-4412-a286-a82362c8858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##7. PyTorch Model (OPTIMIZED)\n",
    "class ChatBotModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ccbcc3-cc2c-4c76-94c6-6e409f89e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.3935\n",
      "Epoch 50, Loss: 3.2516\n",
      "Epoch 100, Loss: 1.2585\n",
      "Epoch 150, Loss: 0.3539\n",
      "Epoch 200, Loss: 0.1450\n",
      "Epoch 250, Loss: 0.0814\n"
     ]
    }
   ],
   "source": [
    "##8. Train Model\n",
    "model = ChatBotModel(len(words), 128, len(classes))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(300):\n",
    "    outputs = model(torch.FloatTensor(X))\n",
    "    loss = criterion(outputs, torch.argmax(torch.FloatTensor(y), dim=1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3532a8ab-0d52-4084-b29c-10b9e6920aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved ✅\n"
     ]
    }
   ],
   "source": [
    "##9. Save Model\n",
    "torch.save(model.state_dict(), \"saved_model/model.pth\")\n",
    "print(\"Model trained and saved ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1261bbc-6127-46c3-9cb8-76ba502dcd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
